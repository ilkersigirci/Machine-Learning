{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quora.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ilkersigirci/ML-with-Colab/blob/master/quora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbTyzA6PgnnC",
        "colab_type": "code",
        "outputId": "99b8fa84-bf56-4725-ee0c-4dbf4fb085cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "import os\n",
        "import pprint\n",
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import linear_model\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import scipy\n",
        "from sklearn.metrics import log_loss\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#embeddings imports\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim import corpora\n",
        "import gensim.downloader as api\n",
        "from gensim.matutils import softcossim\n",
        "!pip install fuzzywuzzy\n",
        "from fuzzywuzzy import fuzz\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "from tqdm import tqdm_notebook\n",
        "from nltk import word_tokenize\n",
        "from scipy.stats import skew, kurtosis\n",
        "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix  \n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/f1/5a267addb30ab7eaa1beab2b9323073815da4551076554ecc890a3595ec9/fuzzywuzzy-0.17.0-py2.py3-none-any.whl\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.17.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR-60uLhrFM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install -U -q kaggle\n",
        "#!mkdir -p ~/.kaggle\n",
        "#!cp drive/My\\ Drive/Colab\\ Notebooks/kaggle.json  ~/.kaggle/\n",
        "#!kaggle datasets list\n",
        "#!kaggle competitions download -c quora-question-pairs -p \"/content/mydata/quora\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KKjhMRPr-YL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir mydata\n",
        "!mkdir mydata/quora"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPDHzfM9rU87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp  drive/My\\ Drive/Colab\\ Notebooks/Dataset/quora/{train.csv,test.csv} mydata/quora/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EepsQICgT92J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('./mydata/quora/train.csv')\n",
        "df.dropna(axis = 0, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKL0jN0C3ppJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.groupby(\"is_duplicate\")['id'].count().plot(kind='bar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_UmJ8o6RnoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(['id', 'qid1', 'qid2'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwEJBh6j-tiG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4BnTb1SSCgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cleaning text\n",
        "import re\n",
        "from string import punctuation\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "SPECIAL_TOKENS = {\n",
        "    'quoted': 'quoted_item',\n",
        "    'non-ascii': 'non_ascii_word',\n",
        "    'undefined': 'something'\n",
        "}\n",
        "\n",
        "def pad_str(s):\n",
        "    return ' '+s+' '\n",
        "\n",
        "def pad_number(pattern):\n",
        "    matched_string = pattern.group(0)\n",
        "    return pad_str(matched_string)\n",
        "\n",
        "def pad_pattern(pattern):\n",
        "    matched_string = pattern.group(0)\n",
        "    return pad_str(matched_string)\n",
        "    \n",
        "def clean(text, stem_words=True):\n",
        "    \n",
        "    if pd.isnull(text):\n",
        "        return ''\n",
        "    \n",
        "    # Empty question   \n",
        "    if type(text) != str or text=='':\n",
        "        return ''\n",
        "    \n",
        "    # Clean the text, with the option to stem words.\n",
        "    # stops = set(stopwords.words(\"english\"))       \n",
        "\n",
        "    # Clean the text\n",
        "    text = re.sub(\"\\'s\", \" \",                       text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\" whats \", \" what is \",           text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"\\'ve\", \" have \",                 text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"can't\", \"can not\",               text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"n't\", \" not \",                   text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"i'm\", \"i am\",                    text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"\\'re\", \" are \",                  text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"\\'d\", \" would \",                 text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"\\'ll\", \" will \",                 text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"e\\.g\\.\", \" eg \",                 text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"b\\.g\\.\", \" bg \",                 text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"(\\d+)(kK)\", \" \\g<1>000 \",        text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"\\(s\\)\", \" \",                     text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"[c-fC-F]\\:\\/\", \" disk \",         text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"e-mail\", \" email \",              text, flags=re.IGNORECASE)\n",
        "    text = re.sub('\\$', \" dollar \",                 text, flags=re.IGNORECASE)\n",
        "    text = re.sub('\\%', \" percent \",                text, flags=re.IGNORECASE)\n",
        "    text = re.sub('\\&', \" and \",                    text, flags=re.IGNORECASE)    \n",
        "    text = re.sub(\"(?<=[0-9])rs \", \" rs \",          text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\" rs(?=[0-9])\", \" rs \",           text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" UK \", \" England \",             text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" india \", \" India \",            text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" switzerland \", \" Switzerland \",text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" china \", \" China \",            text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" chinese \", \" Chinese \",        text, flags=re.IGNORECASE) \n",
        "    text = re.sub(r\" imrovement \", \" improvement \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" intially \", \" initially \",     text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" quora \", \" Quora \",            text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" dms \", \" direct messages \",    text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" actived \", \" active \",         text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" kms \", \" kilometers \",         text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" cs \", \" computer science \",    text, flags=re.IGNORECASE) \n",
        "    text = re.sub(r\" upvote\", \" up vote\",           text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" iPhone \", \" phone \",           text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" \\0rs \", \" rs \",                text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" calender \", \" calendar \",      text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" android \",\" operating system \",text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" ios \", \" operating system \",   text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" gps \", \" GPS \",                text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" gst \", \" GST \",                text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" programing \", \" programming \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" bestfriend \", \" best friend \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" dna \", \" DNA \",                text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" III \", \" 3 \",                  text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" banglore \", \" Banglore \",      text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" J K \", \" JK \",                 text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" J\\.K\\. \", \" JK \",              text, flags=re.IGNORECASE)\n",
        "\n",
        "    text = re.sub(r\" demonitization \", \" demonetization \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub('[^\\x00-\\x7F]+', pad_str(SPECIAL_TOKENS['non-ascii']), text)\n",
        "\n",
        "    text =re.sub('(?<=[0-9])\\,(?=[0-9])',\"\",text, flags=re.IGNORECASE) # remove comma between numbers\n",
        "    \n",
        "    # replace the float numbers with a random number, it will be parsed as number afterward, and also been replaced with word \"number\"    \n",
        "    text = re.sub('[0-9]+\\.[0-9]+', \" 87 \",         text, flags=re.IGNORECASE)\n",
        "\n",
        "    #text = re.sub('[\\!\\?\\@\\^\\+\\*\\/\\,\\~\\|\\`\\=\\:\\;\\.\\#\\\\\\]', pad_pattern, text)        \n",
        "    #text = re.sub(\"(the[\\s]+|The[\\s]+)?U\\.S\\.A\\.\", \" America \", text, flags=re.IGNORECASE)\n",
        "    #text = re.sub(\"(the[\\s]+|The[\\s]+)?United State(s)?\", \" America \", text, flags=re.IGNORECASE)\n",
        "    \n",
        "    # all numbers should separate from words, this is too aggressive\n",
        "    # text = re.sub('[0-9]+', pad_number,  text, flags=re.IGNORECASE)  \n",
        "    \n",
        "    # Remove punctuation from text\n",
        "    text = ''.join([c for c in text if c not in punctuation]).lower()\n",
        "        \n",
        "    return text  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx8lrg8xZJOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['question1'] = df['question1'].apply(clean)\n",
        "df['question2'] = df['question2'].apply(clean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGh_e9CZ_fnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfSub =  df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_Qkkyn_AI9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#BoW + XgBoost Model\n",
        "# train -> 0.82 / test -> 0.75\n",
        "\n",
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
        "count_vect.fit(pd.concat((df['question1'],df['question2'])).unique())\n",
        "trainq1_trans = count_vect.transform(df['question1'].values)\n",
        "trainq2_trans = count_vect.transform(df['question2'].values)\n",
        "labels = df['is_duplicate'].values\n",
        "X = scipy.sparse.hstack((trainq1_trans,trainq2_trans))\n",
        "y = labels\n",
        "X_train,X_valid,y_train,y_valid = train_test_split(X,y, test_size = 0.33, random_state = 42)\n",
        "xgb_model = xgb.XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8).fit(X_train, y_train) \n",
        "xgb_prediction = xgb_model.predict(X_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYf-lhLtgjKk",
        "colab_type": "code",
        "outputId": "55e0d28e-5a6e-45c5-a8b3-c01ed1a14e02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
        "\n",
        "print('training score:', f1_score(y_train, xgb_model.predict(X_train), average='macro'))\n",
        "print('validation score:', f1_score(y_valid, xgb_model.predict(X_valid), average='macro'))\n",
        "print(classification_report(y_valid, xgb_prediction))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training score: 0.8292012350767584\n",
            "validation score: 0.7590104068777661\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.90      0.84     84267\n",
            "           1       0.78      0.60      0.68     49148\n",
            "\n",
            "    accuracy                           0.79    133415\n",
            "   macro avg       0.78      0.75      0.76    133415\n",
            "weighted avg       0.79      0.79      0.78    133415\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm5LHqyepJex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Word level TF-IDF\n",
        "# train -> 0.84 / test -> 0.75\n",
        "\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
        "tfidf_vect.fit(pd.concat((df['question1'],df['question2'])).unique())\n",
        "trainq1_trans = tfidf_vect.transform(df['question1'].values)\n",
        "trainq2_trans = tfidf_vect.transform(df['question2'].values)\n",
        "labels = df['is_duplicate'].values\n",
        "X = scipy.sparse.hstack((trainq1_trans,trainq2_trans))\n",
        "y = labels\n",
        "X_train,X_valid,y_train,y_valid = train_test_split(X,y, test_size = 0.33, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl5nsJvHpUMj",
        "colab_type": "code",
        "outputId": "6de2bc9d-514c-47cb-d436-5bdbd3a25665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Combine it with xgboost\n",
        "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
        "xgb_model = xgb.XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8).fit(X_train, y_train) \n",
        "xgb_prediction = xgb_model.predict(X_valid)\n",
        "print('word level tf-idf training score:', f1_score(y_train, xgb_model.predict(X_train), average='macro'))\n",
        "print('word level tf-idf validation score:', f1_score(y_valid, xgb_model.predict(X_valid), average='macro'))\n",
        "print(classification_report(y_valid, xgb_prediction))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word level tf-idf training score: 0.8893228534163832\n",
            "word level tf-idf validation score: 0.761087480236885\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.90      0.84     84267\n",
            "           1       0.78      0.60      0.68     49148\n",
            "\n",
            "    accuracy                           0.79    133415\n",
            "   macro avg       0.79      0.75      0.76    133415\n",
            "weighted avg       0.79      0.79      0.78    133415\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PBgozO3p5dx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#N-gram(2,3) level TF-IDF\n",
        "# train -> 0.71 / test -> 0.67\n",
        "\n",
        "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram.fit(pd.concat((df['question1'],df['question2'])).unique())\n",
        "trainq1_trans = tfidf_vect_ngram.transform(df['question1'].values)\n",
        "trainq2_trans = tfidf_vect_ngram.transform(df['question2'].values)\n",
        "labels = df['is_duplicate'].values\n",
        "X = scipy.sparse.hstack((trainq1_trans,trainq2_trans))\n",
        "y = labels\n",
        "X_train,X_valid,y_train,y_valid = train_test_split(X,y, test_size = 0.33, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M3cwGB5qD2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Combine it with xgboost\n",
        "xgb_model = xgb.XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8).fit(X_train, y_train) \n",
        "xgb_prediction = xgb_model.predict(X_valid)\n",
        "print('n-gram level tf-idf training score:', f1_score(y_train, xgb_model.predict(X_train), average='macro'))\n",
        "print('n-gram level tf-idf validation score:', f1_score(y_valid, xgb_model.predict(X_valid), average='macro'))\n",
        "print(classification_report(y_valid, xgb_prediction))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK81pBHBqs2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Character Level TF-IDF + XgBoost -> HIGHEST\n",
        "# train -> 0.98 / test -> 0.80\n",
        "\n",
        "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram_chars.fit(pd.concat((df['question1'],df['question2'])).unique())\n",
        "trainq1_trans = tfidf_vect_ngram_chars.transform(df['question1'].values)\n",
        "trainq2_trans = tfidf_vect_ngram_chars.transform(df['question2'].values)\n",
        "labels = df['is_duplicate'].values\n",
        "X = scipy.sparse.hstack((trainq1_trans,trainq2_trans))\n",
        "y = labels\n",
        "X_train,X_valid,y_train,y_valid = train_test_split(X,y, test_size = 0.33, random_state = 42)\n",
        "xgb_model = xgb.XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8).fit(X_train, y_train) \n",
        "xgb_prediction = xgb_model.predict(X_valid)\n",
        "print('character level tf-idf training score:', f1_score(y_train, xgb_model.predict(X_train), average='macro'))\n",
        "print('character level tf-idf validation score:', f1_score(y_valid, xgb_model.predict(X_valid), average='macro'))\n",
        "print(classification_report(y_valid, xgb_prediction))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wv8todrUtVCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#######################################################################################################\n",
        "##################################### Word Embeddings Test ############################################\n",
        "#######################################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNKvZO7vQNAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Yp81gO8tdk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('./mydata/quora/train.csv')\n",
        "df = df.dropna(how=\"any\").reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aSVlsbuwXXH",
        "colab_type": "code",
        "outputId": "a5431942-b950-468f-e535-25949d33e944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#Word Mover's Distance (WMD)\n",
        "\n",
        "#Copy GoogleNews-vectors-negative300.bin.gz\n",
        "!cp  drive/My\\ Drive/Colab\\ Notebooks/Dataset/quora/GoogleNews-vectors-negative300.bin.gz mydata/quora/\n",
        "\n",
        "googlenews_corpus_path = 'mydata/quora/GoogleNews-vectors-negative300.bin.gz'\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(googlenews_corpus_path, binary=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbJLLXu8J-3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "question1 = 'What would a Trump presidency mean for current international master’s students on an F1 visa?'\n",
        "question2 = 'How will a Trump presidency affect the students presently in US or planning to study in US?'\n",
        "\n",
        "question1 = question1.lower().split()\n",
        "question2 = question2.lower().split()\n",
        "\n",
        "question1 = [w for w in question1 if w not in stop_words]\n",
        "question2 = [w for w in question2 if w not in stop_words]\n",
        "\n",
        "#normalization decreases the length in duplicate labeled question\n",
        "model.init_sims(replace=True) #normalize word2vec vectors\n",
        "distance = model.wmdistance(question1, question2)             #distance = 0.7589\n",
        "print('distance = %.4f' % distance)\n",
        "################################################################################\n",
        "question3 = 'Why am I mentally very lonely? How can I solve it?'\n",
        "question4 = 'Find the remainder when [math]23^{24}[/math] is divided by 24,23?'\n",
        "\n",
        "question3 = question3.lower().split()\n",
        "question4 = question4.lower().split()\n",
        "\n",
        "question3 = [w for w in question3 if w not in stop_words]\n",
        "question4 = [w for w in question4 if w not in stop_words]\n",
        "\n",
        "#normalization doesn't affect the length in non duplicate labeled question\n",
        "model.init_sims(replace=True) #normalize word2vec vectors\n",
        "distance = model.wmdistance(question3, question4)             #distance = 1.2637\n",
        "print('distance = %.4f' % distance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rPSz1Y0RIon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#soft cosine\n",
        "from gensim import corpora\n",
        "\n",
        "documents = [question1, question2, question3, question4]\n",
        "dictionary = corpora.Dictionary(documents)\n",
        "corpus = [dictionary.doc2bow(document) for document in documents]\n",
        "\n",
        "#Convert the sentences into bag-of-words vectors.\n",
        "question1 = dictionary.doc2bow(question1)\n",
        "question2 = dictionary.doc2bow(question2)\n",
        "question3 = dictionary.doc2bow(question3)\n",
        "question4 = dictionary.doc2bow(question4)\n",
        "\n",
        "import gensim.downloader as api\n",
        "\n",
        "w2v_model = api.load(\"glove-wiki-gigaword-50\")\n",
        "similarity_matrix = w2v_model.similarity_matrix(dictionary)\n",
        "\n",
        "from gensim.matutils import softcossim\n",
        "\n",
        "#similarity = 0.7611\n",
        "similarity = softcossim(question1, question2, similarity_matrix)\n",
        "print('similarity = %.4f' % similarity)\n",
        "\n",
        "#similarity = 0.2030\n",
        "similarity = softcossim(question3, question4, similarity_matrix)\n",
        "print('similarity = %.4f' % similarity)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls492394aBFO",
        "colab_type": "code",
        "outputId": "78762cbf-4f01-4fa0-bce3-7de6b1b74eeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#FuzzyWuzzy\n",
        "from fuzzywuzzy import fuzz\n",
        "\n",
        "question1 = 'What would a Trump presidency mean for current international master’s students on an F1 visa?'\n",
        "question2 = 'How will a Trump presidency affect the students presently in US or planning to study in US?'\n",
        "question3 = 'Why am I mentally very lonely? How can I solve it?'\n",
        "question4 = 'Find the remainder when [math]23^{24}[/math] is divided by 24,23?'\n",
        "\n",
        "# ratio            -> 51 -> compares the entire string similarity, in order\n",
        "# partial_ratio    -> 52 -> compares partial string similarity.\n",
        "# token_sort_ratio -> 46 -> ignores word order.\n",
        "# token_set_ratio  -> 52 -> ignores duplicated words\n",
        "\n",
        "\n",
        "fuzz.partial_token_set_ratio(question1, question2) # 100\n",
        "fuzz.partial_token_set_ratio(question3, question4) # 37"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmppAhe1_DF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#######################################################################################################\n",
        "############################## Word Embeddings Feature Engineering ####################################\n",
        "#######################################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0ykH3sa_I1z",
        "colab_type": "code",
        "outputId": "b34feea8-b4cc-4be0-c06b-72c1a39bed22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def wmd(q1, q2):\n",
        "    q1 = str(q1).lower().split()\n",
        "    q2 = str(q2).lower().split()\n",
        "    stop_words = stopwords.words('english')\n",
        "    q1 = [w for w in q1 if w not in stop_words]\n",
        "    q2 = [w for w in q2 if w not in stop_words]\n",
        "    return model.wmdistance(q1, q2)\n",
        "\n",
        "def norm_wmd(q1, q2):\n",
        "    q1 = str(q1).lower().split()\n",
        "    q2 = str(q2).lower().split()\n",
        "    stop_words = stopwords.words('english')\n",
        "    q1 = [w for w in q1 if w not in stop_words]\n",
        "    q2 = [w for w in q2 if w not in stop_words]\n",
        "    return norm_model.wmdistance(q1, q2)\n",
        "\n",
        "def my_wmd(q1, q2):\n",
        "    q1 = str(q1).lower().split()\n",
        "    q2 = str(q2).lower().split()\n",
        "    stop_words = stopwords.words('english')\n",
        "    q1 = [w for w in q1 if w not in stop_words]\n",
        "    q2 = [w for w in q2 if w not in stop_words]\n",
        "    return model.wmdistance(q1, q2)\n",
        "  \n",
        "\n",
        "nltk.download('punkt')\n",
        "def sent2vec(s):\n",
        "    words = str(s).lower()\n",
        "    words = word_tokenize(words)\n",
        "    words = [w for w in words if not w in stop_words]\n",
        "    words = [w for w in words if w.isalpha()]\n",
        "    M = []\n",
        "    for w in words:\n",
        "        try:\n",
        "            M.append(model[w])\n",
        "        except:\n",
        "            continue\n",
        "    M = np.array(M)\n",
        "    print(M)\n",
        "    v = M.sum(axis=0)\n",
        "    return v / np.sqrt((v ** 2).sum())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b3Lobh1B2TS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(['id', 'qid1', 'qid2'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZfdyXbjAYMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### NEW FEATURES ###\n",
        "\n",
        "# The length of word.\n",
        "# The length of character.\n",
        "# The length of common word between question1 and question2.\n",
        "# The length difference between question1 and question2.\n",
        "# The Cosine distance between vectors question1 and question2.\n",
        "# The City block (Manhattan) distance between vectors question1 and question2.\n",
        "# The Jaccard distance between vectors question1 and question2.\n",
        "# The Canberra distance between vectors question1 and question2.\n",
        "# The Euclidean distance between vectors question1 and question2.\n",
        "# The Minkowski distance between vectors question1 and question2.\n",
        "# The Bray-Curtis distance between vectors question1 and question2.\n",
        "# The skewness and kurtosis of vectors question1 and question2.\n",
        "# WMD\n",
        "# normalized WMD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77jrvyqmByMR",
        "colab_type": "code",
        "outputId": "30278a55-5c83-47a0-eb24-466a8c811e0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "df['len_q1'] = df.question1.apply(lambda x: len(str(x)))\n",
        "print(\"len_q1 done..\")\n",
        "df['len_q2'] = df.question2.apply(lambda x: len(str(x)))\n",
        "print(\"len_q2 done..\")\n",
        "df['diff_len'] = df.len_q1 - df.len_q2\n",
        "print(\"diff_len done..\")\n",
        "df['len_char_q1'] = df.question1.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
        "print(\"len_char_q1 done..\")\n",
        "df['len_char_q2'] = df.question2.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
        "print(\"len_char_q2 done..\")\n",
        "df['len_word_q1'] = df.question1.apply(lambda x: len(str(x).split()))\n",
        "print(\"len_word_q1 done..\")\n",
        "df['len_word_q2'] = df.question2.apply(lambda x: len(str(x).split()))\n",
        "print(\"len_word_q2 done..\")\n",
        "df['common_words'] = df.apply(lambda x: len(set(str(x['question1']).lower().split()).intersection(set(str(x['question2']).lower().split()))), axis=1)\n",
        "print(\"common_words done..\")\n",
        "df['fuzz_ratio'] = df.apply(lambda x: fuzz.ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
        "print(\"fuzz_ratio done..\")\n",
        "df['fuzz_partial_ratio'] = df.apply(lambda x: fuzz.partial_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
        "print(\"fuzz_partial_ratio done..\")\n",
        "df['fuzz_partial_token_set_ratio'] = df.apply(lambda x: fuzz.partial_token_set_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
        "print(\"fuzz_partial_token_set_ratio done..\")\n",
        "df['fuzz_partial_token_sort_ratio'] = df.apply(lambda x: fuzz.partial_token_sort_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
        "print(\"fuzz_partial_token_sort_ratio done..\")\n",
        "df['fuzz_token_set_ratio'] = df.apply(lambda x: fuzz.token_set_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
        "print(\"fuzz_token_set_ratio done..\")\n",
        "df['fuzz_token_sort_ratio'] = df.apply(lambda x: fuzz.token_sort_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
        "print(\"fuzz_token_sort_ratio done..\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len_q1 done..\n",
            "len_q2 done..\n",
            "diff_len done..\n",
            "len_char_q1 done..\n",
            "len_char_q2 done..\n",
            "len_word_q1 done..\n",
            "len_word_q2 done..\n",
            "common_words done..\n",
            "fuzz_ratio done..\n",
            "fuzz_partial_ratio done..\n",
            "fuzz_partial_token_set_ratio done..\n",
            "fuzz_partial_token_sort_ratio done..\n",
            "fuzz_token_set_ratio done..\n",
            "fuzz_token_sort_ratio done..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "walHsIWwB9pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ykj_8BvnHR1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfExtraFeatures = df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRM5giSHEGLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#word2vec modeling\n",
        "#googlenews_corpus_path = 'mydata/quora/GoogleNews-vectors-negative300.bin.gz'\n",
        "#model = gensim.models.KeyedVectors.load_word2vec_format(googlenews_corpus_path, binary=True)\n",
        "#df['wmd'] = df.apply(lambda x: wmd(x['question1'], x['question2']), axis=1)\n",
        "df['wmd'] = df.apply(lambda x: my_wmd(x['question1'], x['question2']), axis=1)\n",
        "\n",
        "#normalized word2vec modeling\n",
        "#norm_model = gensim.models.KeyedVectors.load_word2vec_format(googlenews_corpus_path, binary=True)\n",
        "#norm_model.init_sims(replace=True)\n",
        "#df['norm_wmd'] = df.apply(lambda x: norm_wmd(x['question1'], x['question2']), axis=1)\n",
        "model.init_sims(replace=True)\n",
        "df['norm_wmd'] = df.apply(lambda x: my_wmd(x['question1'], x['question2']), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUe_tTM4DmuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv(\"quora_middle.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeJ1NHGjFCSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "question1_vectors = np.zeros((df.shape[0], 300))\n",
        "\n",
        "for i, q in enumerate(tqdm_notebook(df.question1.values)):\n",
        "    question1_vectors[i, :] = sent2vec(q)\n",
        "    \n",
        "question2_vectors  = np.zeros((df.shape[0], 300))\n",
        "for i, q in enumerate(tqdm_notebook(df.question2.values)):\n",
        "    question2_vectors[i, :] = sent2vec(q)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48YADzRRGZ8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['cosine_distance'] = [cosine(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors), np.nan_to_num(question2_vectors))]\n",
        "df['cityblock_distance'] = [cityblock(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors), np.nan_to_num(question2_vectors))]\n",
        "df['jaccard_distance'] = [jaccard(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors), np.nan_to_num(question2_vectors))]\n",
        "df['canberra_distance'] = [canberra(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors), np.nan_to_num(question2_vectors))]\n",
        "df['euclidean_distance'] = [euclidean(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors), np.nan_to_num(question2_vectors))]\n",
        "df['minkowski_distance'] = [minkowski(x, y, 3) for (x, y) in zip(np.nan_to_num(question1_vectors), np.nan_to_num(question2_vectors))]\n",
        "df['braycurtis_distance'] = [braycurtis(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors), np.nan_to_num(question2_vectors))]\n",
        "df['skew_q1vec'] = [skew(x) for x in np.nan_to_num(question1_vectors)]\n",
        "df['skew_q2vec'] = [skew(x) for x in np.nan_to_num(question2_vectors)]\n",
        "df['kur_q1vec'] = [kurtosis(x) for x in np.nan_to_num(question1_vectors)]\n",
        "df['kur_q2vec'] = [kurtosis(x) for x in np.nan_to_num(question2_vectors)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hqlB3t5Gm1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['is_duplicate'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3DO1G4IGvSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cosine_distance, jaccard_distance and braycurtis_distance have null values\n",
        "df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o84ZhMjMGzTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(['question1', 'question2'], axis=1, inplace=True)\n",
        "df = df[pd.notnull(df['cosine_distance'])]\n",
        "df = df[pd.notnull(df['jaccard_distance'])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZzI6pIWHDid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix  \n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X = df.loc[:, df.columns != 'is_duplicate']\n",
        "y = df.loc[:, df.columns == 'is_duplicate']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCdcvW_zHPYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "model = xgb.XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8).fit(X_train, y_train.values.ravel()) \n",
        "prediction = model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, prediction)  \n",
        "print(cm)  \n",
        "print('Accuracy', accuracy_score(y_test, prediction))\n",
        "print(classification_report(y_test, prediction))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}